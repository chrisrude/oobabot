
# Welcome to Oobabot!
#
# This is the configuration file for Oobabot.  It is a YAML file, and
# comments are allowed.  Oobabot attempts to load a file named
# "config.yml" from the current directory when it is run.
#

version: 0.2.3

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# persona
# .
persona:

  # Name the AI will use to refer to itself
  #   default: oobabot
  ai_name:

  # This prefix will be added in front of every user-supplied request.  This is useful for
  # setting up a 'character' for the bot to play.  Alternatively, this can be set with the
  # OOBABOT_PERSONA environment variable.
  persona:

  # Path to a file containing a persona.  This can be just a single string, a json file in
  # the common "tavern" formats, or a yaml file in the Oobabooga format.  With a single
  # string, the persona will be set to that string.  Otherwise, the ai_name and persona will
  # be overwritten with the values in the file.  Also, the wakewords will be extended to
  # include the character's own name.
  #   default:
  persona_file:

  # One or more words that the bot will listen for. The bot will listen in all discord
  # channels it can access for one of these words to be mentioned, then reply to any
  # messages it sees with a matching word. The bot will always reply to @-mentions and
  # direct messages, even if no wakewords are supplied.
  #   default: ['oobabot']
  wakewords:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# discord
# .
discord:

  # Token to log into Discord with.  For security purposes it's strongly recommended that
  # you set this via the DISCORD_TOKEN environment variable instead, if possible.
  discord_token: ''

  # Post the entire response as a single message, rather than splitting it into separate
  # messages by sentence.
  #   default: False
  dont_split_responses:

  # Number of lines of chat history the AI will see when generating a response.
  #   default: 7
  history_lines:

  # If set, the bot will not respond to direct messages.
  #   default: False
  ignore_dms:

  # Set the log level.  Valid values are:
  # CRITICAL, ERROR, WARNING, INFO, DEBUG
  #   default: DEBUG
  log_level:

  # If set, the bot will generate a thread to respond in if it is not already in one.
  #   default: False
  reply_in_thread:

  # A list of strings that will cause the bot to stop generating a response when
  # encountered.
  #   default: ['### End of Transcript ###<|endoftext|>', '<|endoftext|>']
  stop_markers:

  # FEATURE PREVIEW: Stream responses into a single message as they are generated. Note: may
  # be janky
  #   default: False
  stream_responses:

  # FEATURE PREVIEW: When streaming responses, cap the rate at which we send updates to
  # Discord to be no more than once per this many seconds.  This does not guarantee that
  # updates will be sent this fast.  Only that they will not be sent any faster than this
  # rate.  This is useful because Discord has a rate limit on how often you can send
  # messages, and if you exceed it, the updates will suddenly become slow.  Example: 0.2
  # means we will send updates no faster than 5 times per second.
  #   default: 0.7
  stream_responses_speed_limit:

  # Adds a limit to the number of channels the bot will post unsolicited messages in at the
  # same time.  This is to prevent the bot from being too noisy in large servers.  When set,
  # only the most recent N channels the bot has been summoned in will have a chance of
  # receiving an unsolicited message.  The bot will still respond to @-mentions and wake
  # words in any channel it can access.  Set to 0 to disable this feature.
  #   default: 3
  unsolicited_channel_cap:

  # If set, the bot will not reply to any messages that do not @-mention it or include a
  # wakeword.  If unsolicited replies are disabled, the unsolicited_channel_cap setting will
  # have no effect.
  #   default: False
  disable_unsolicited_replies:

  # FEATURE PREVIEW: Path to the Discrivener executable. Will enable prototype voice
  # integration.
  #   default:
  discrivener_location:

  # FEATURE PREVIEW: Path to the Discrivener model to load.  Required if
  # discrivener_location is set.
  #   default:
  discrivener_model_location:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# oobabooga
# .
oobabooga:

  # Base URL for the oobabooga instance.  This should be ws://hostname[:port] for plain
  # websocket connections, or wss://hostname[:port] for websocket connections over TLS.
  #   default: ws://localhost:5005
  base_url:

  # Print all AI input and output to STDOUT.
  #   default: False
  log_all_the_things:

  # A regex that will be used to extract message lines from the AI's output.  The first
  # capture group will be used as the message.  If this is not set, the entire output will
  # be used as the message.
  #   default:
  message_regex:

  # A dictionary which will be passed straight through to Oobabooga on every request.  Feel
  # free to add additional simple parameters here as Oobabooga's API evolves. See
  # Oobabooga's documentation for what these parameters mean.
  request_params:
    max_new_tokens: 250
    do_sample: true
    temperature: 1.3
    top_p: 0.1
    typical_p: 1
    epsilon_cutoff: 0
    eta_cutoff: 0
    tfs: 1
    top_a: 0
    repetition_penalty: 1.18
    top_k: 40
    min_length: 0
    no_repeat_ngram_size: 0
    num_beams: 1
    penalty_alpha: 0
    length_penalty: 1
    early_stopping: false
    mirostat_mode: 0
    mirostat_tau: 5
    mirostat_eta: 0.1
    seed: -1
    add_bos_token: true
    truncation_length: 2048
    ban_eos_token: false
    skip_special_tokens: true
    stopping_strings: []

  # When running inside the Oobabooga plugin, automatically connect to Discord when
  # Oobabooga starts.  This has no effect when running from the command line.
  #   default: False
  plugin_auto_start:

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# stable_diffusion
# .
stable_diffusion:

  # When one of these words is used in a message, the bot will generate an image.
  #   default: ['draw me', 'drawing', 'photo', 'pic', 'picture', 'image', 'sketch']
  image_words:

  # URL for an AUTOMATIC1111 Stable Diffusion server.
  #   default:
  stable_diffusion_url:

  # This will be appended to every image generation prompt sent to Stable Diffusion.
  #   default:
  extra_prompt_text:

  # A dictionary which will be passed straight through to Stable Diffusion on every request.
  # Feel free to add additional simple parameters here as Stable Diffusion's API evolves.
  # See Stable Diffusion's documentation for what these parameters mean.
  request_params:
    cfg_scale: 7
    do_not_save_samples: true
    do_not_save_grid: true
    enable_hr: false
    model: ''
    negative_prompt: animal harm, suicide, loli, nsfw
    negative_prompt_nsfw: animal harm, suicide, loli
    sampler_name: ''
    seed: -1
    steps: 30
    width: 512
    height: 512

  # These parameters can be overridden by the Discord user by including them in their image
  # generation request.  The format for this is: param_name=value  This is a whitelist of
  # parameters that can be overridden. They must be simple parameters (strings, numbers,
  # booleans), and they must be in the request_params dictionary.  The value the user inputs
  # will be checked against the type from the request_params dictionary, and if it doesn't
  # match, the default value will be used instead.  Otherwise, this value will be passed
  # through to Stable Diffusion without any changes, so be mindful of what you allow here.
  # It could potentially be used to inject malicious values into your SD server.  For
  # example, steps=1000000 could be bad for your server.
  user_override_params:
    - cfg_scale
    - enable_hr
    - model
    - negative_prompt
    - sampler_name
    - seed
    - height
    - width

# # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # # #
# template
# .
template:

  # Displayed in Discord after a successful /lobotomize command.  Both the discord users and
  # the bot AI will see this message.
  # .
  # Allowed tokens: {AI_NAME}, {USER_NAME}
  # .
  #   default:  Ummmm... what were we talking about?
  command_lobotomize_response:

  # The main prompt sent to Oobabooga to generate a response from the bot AI.  The AI's
  # reply to this prompt will be sent to discord as the bot's response.
  # .
  # Allowed tokens: {AI_NAME}, {IMAGE_COMING}, {MESSAGE_HISTORY}, {PERSONA}
  # .
  #   default:  You are in a chat room with multiple participants. Below is a transcript of
  # recent messages in the conversation. Write the next one to three messages that you would
  # send in this conversation, from the point of view of the participant named {AI_NAME}.
  # {PERSONA}  All responses you write must be from the point of view of {AI_NAME}. ###
  # Transcript: {MESSAGE_HISTORY} {IMAGE_COMING}
  prompt:

  # Part of the AI response-generation prompt, this is used to render a single line of chat
  # history.  A list of these, one for each past chat message, will become {MESSAGE_HISTORY}
  # and inserted into the main prompt
  # .
  # Allowed tokens: {USER_MESSAGE}, {USER_NAME}
  # .
  #   default:  {USER_NAME} says: {USER_MESSAGE}
  prompt_history_line:

  # Part of the AI response-generation prompt, this is used to inform the AI that it is in
  # the process of generating an image.
  # .
  # Allowed tokens: {AI_NAME}
  # .
  #   default:  {AI_NAME}: is currently generating an image, as requested.
  prompt_image_coming:
